{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4067718,"sourceType":"datasetVersion","datasetId":2407911}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:04:37.159141Z","iopub.execute_input":"2025-11-23T11:04:37.159507Z","iopub.status.idle":"2025-11-23T11:04:37.485286Z","shell.execute_reply.started":"2025-11-23T11:04:37.159482Z","shell.execute_reply":"2025-11-23T11:04:37.484601Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/vietnam-weather-data/weather.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 1: Import libraries\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score,\n    roc_auc_score,\n    classification_report,\n    confusion_matrix\n)\n\nimport xgboost as xgb\nimport joblib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:04:37.486255Z","iopub.execute_input":"2025-11-23T11:04:37.486577Z","iopub.status.idle":"2025-11-23T11:04:38.008301Z","shell.execute_reply.started":"2025-11-23T11:04:37.486558Z","shell.execute_reply":"2025-11-23T11:04:38.007359Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\nDATA_PATH = \"/kaggle/input/vietnam-weather-data/weather.csv\"\ndf = pd.read_csv(DATA_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:09:14.463863Z","iopub.execute_input":"2025-11-23T11:09:14.464497Z","iopub.status.idle":"2025-11-23T11:09:14.569942Z","shell.execute_reply.started":"2025-11-23T11:09:14.464477Z","shell.execute_reply":"2025-11-23T11:09:14.569054Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Cell 3: Basic cleaning & feature/label engineering\n\nprint(\"Columns trong dataset:\", df.columns.tolist())\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n\n# Map tên cột: dataset dùng lowercase, ta rename sang dạng dễ hiểu\n# CHÚ Ý: 'humid' chứ KHÔNG PHẢI 'humidi'\ndf = df.rename(columns={\n    'province': 'Province',\n    'max':      'MaxTemp',\n    'min':      'MinTemp',\n    'rain':     'Rainfall',\n    'humidi':    'Humidity',   # <-- sửa ở đây\n    'date':     'Date'\n})\n\n# Giữ các cột quan trọng\nrequired_cols = [\"Province\", \"Date\", \"MaxTemp\", \"MinTemp\", \"Rainfall\", \"Humidity\"]\nmissing_cols = [c for c in required_cols if c not in df.columns]\nprint(\"\\nMissing columns:\", missing_cols)\nif missing_cols:\n    raise ValueError(f\"Thiếu cột: {missing_cols}\")\n\n# Drop rows thiếu dữ liệu quan trọng\ndf = df.dropna(subset=required_cols).copy()\nprint(f\"\\nSau khi dropna: {len(df)} rows\")\n\n# Chuyển Date sang datetime\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\n# Tính nhiệt độ trung bình trong ngày\ndf[\"TempMean\"] = (df[\"MaxTemp\"] + df[\"MinTemp\"]) / 2.0\n\n# Sắp xếp theo Province + Date\ndf = df.sort_values([\"Province\", \"Date\"]).reset_index(drop=True)\n\n# Tạo RainTomorrow = Rainfall ngày hôm sau cùng tỉnh\ndf[\"RainTomorrow\"] = df.groupby(\"Province\")[\"Rainfall\"].shift(-1)\n\n# Bỏ hàng cuối cùng mỗi tỉnh (RainTomorrow = NaN)\ndf = df.dropna(subset=[\"RainTomorrow\"]).copy()\nprint(f\"Sau khi tạo RainTomorrow: {len(df)} rows\")\n\n# Label heavy_rain_tomorrow: mưa >= 20mm coi là mưa lớn\nHEAVY_RAIN_THRESHOLD = 20.0  # mm\ndf[\"HeavyRainTomorrow\"] = (df[\"RainTomorrow\"] >= HEAVY_RAIN_THRESHOLD).astype(int)\n\nprint(\"\\n=== Sample data ===\")\nprint(df[[\"Province\", \"Date\", \"TempMean\", \"Humidity\",\n          \"Rainfall\", \"RainTomorrow\", \"HeavyRainTomorrow\"]].head(10))\n\nprint(\"\\n=== Label distribution ===\")\nprint(df[\"HeavyRainTomorrow\"].value_counts(normalize=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:09:40.664489Z","iopub.execute_input":"2025-11-23T11:09:40.664836Z","iopub.status.idle":"2025-11-23T11:09:40.803310Z","shell.execute_reply.started":"2025-11-23T11:09:40.664819Z","shell.execute_reply":"2025-11-23T11:09:40.802471Z"}},"outputs":[{"name":"stdout","text":"Columns trong dataset: ['province', 'max', 'min', 'wind', 'wind_d', 'rain', 'humidi', 'cloud', 'pressure', 'date']\n\nFirst few rows:\n   province  max  min  wind wind_d  rain  humidi  cloud  pressure        date\n0  Bac Lieu   27   22    17    NNE   6.9      90     71      1010  2009-01-01\n1  Bac Lieu   31   25    20    ENE   0.0      64     24      1010  2010-01-01\n2  Bac Lieu   29   24    14      E   0.0      75     45      1008  2011-01-01\n3  Bac Lieu   30   24    30      E   0.0      79     52      1012  2012-01-01\n4  Bac Lieu   31   25    20    ENE   0.0      70     24      1010  2013-01-01\n\nMissing columns: []\n\nSau khi dropna: 181960 rows\nSau khi tạo RainTomorrow: 181920 rows\n\n=== Sample data ===\n   Province       Date  TempMean  Humidity  Rainfall  RainTomorrow  \\\n0  Bac Lieu 2009-01-01      24.5        90       6.9           0.5   \n1  Bac Lieu 2009-01-02      25.0        85       0.5          16.7   \n2  Bac Lieu 2009-01-03      22.0        91      16.7           2.2   \n3  Bac Lieu 2009-01-04      24.0        86       2.2           0.0   \n4  Bac Lieu 2009-01-05      25.5        81       0.0           0.3   \n5  Bac Lieu 2009-01-06      26.5        81       0.3           1.9   \n6  Bac Lieu 2009-01-07      26.5        83       1.9           1.2   \n7  Bac Lieu 2009-01-08      25.5        81       1.2           0.0   \n8  Bac Lieu 2009-01-09      24.5        74       0.0           0.0   \n9  Bac Lieu 2009-01-10      22.0        69       0.0           0.0   \n\n   HeavyRainTomorrow  \n0                  0  \n1                  0  \n2                  0  \n3                  0  \n4                  0  \n5                  0  \n6                  0  \n7                  0  \n8                  0  \n9                  0  \n\n=== Label distribution ===\nHeavyRainTomorrow\n0    0.914572\n1    0.085428\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 4: Train/Val/Test split (time-based)\n\n# Sắp xếp theo thời gian (dùng cột \"Date\" sau khi rename)\ndf = df.sort_values(\"Date\").reset_index(drop=True)\n\nn = len(df)\ntest_size = int(n * 0.2)\n\ntrainval_df = df.iloc[:-test_size]\ntest_df     = df.iloc[-test_size:]\n\nprint(\"Train+Val size:\", len(trainval_df), \"Test size:\", len(test_df))\n\nfeature_cols_tiny = [\"TempMean\", \"Humidity\"]\n\nX_trainval = trainval_df[feature_cols_tiny]\ny_trainval = trainval_df[\"HeavyRainTomorrow\"]\n\nX_test = test_df[feature_cols_tiny]\ny_test = test_df[\"HeavyRainTomorrow\"]\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_trainval, y_trainval,\n    test_size=0.2,\n    random_state=42,\n    stratify=y_trainval\n)\n\nlen(X_train), len(X_val), len(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:11:04.015632Z","iopub.execute_input":"2025-11-23T11:11:04.015899Z","iopub.status.idle":"2025-11-23T11:11:04.115481Z","shell.execute_reply.started":"2025-11-23T11:11:04.015884Z","shell.execute_reply":"2025-11-23T11:11:04.114660Z"}},"outputs":[{"name":"stdout","text":"Train+Val size: 145536 Test size: 36384\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(116428, 29108, 36384)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(\n    max_iter=1000,\n    class_weight=\"balanced\",\n    n_jobs=-1\n)\n\nlog_reg.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:11:13.270996Z","iopub.execute_input":"2025-11-23T11:11:13.271272Z","iopub.status.idle":"2025-11-23T11:11:14.321766Z","shell.execute_reply.started":"2025-11-23T11:11:13.271255Z","shell.execute_reply":"2025-11-23T11:11:14.320300Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(class_weight='balanced', max_iter=1000, n_jobs=-1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=-1)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n\ndef eval_binary_clf(name, model, X_tr, y_tr, X_v, y_v, X_te, y_te):\n    print(f\"\\n==== {name} ====\")\n    for split_name, X_split, y_split in [\n        (\"Train\", X_tr, y_tr),\n        (\"Val\",   X_v, y_v),\n        (\"Test\",  X_te, y_te),\n    ]:\n        y_prob = model.predict_proba(X_split)[:, 1]\n        y_pred = (y_prob >= 0.5).astype(int)\n\n        acc = accuracy_score(y_split, y_pred)\n        auc = roc_auc_score(y_split, y_prob)\n\n        print(f\"{split_name}: Acc={acc:.3f}, AUC={auc:.3f}\")\n\n    print(\"\\n--- Classification report (Test) ---\")\n    y_prob_test = model.predict_proba(X_te)[:, 1]\n    y_pred_test = (y_prob_test >= 0.5).astype(int)\n    print(classification_report(y_te, y_pred_test))\n\n    print(\"\\n--- Confusion matrix (Test) ---\")\n    print(confusion_matrix(y_te, y_pred_test))\n\n\neval_binary_clf(\n    \"Logistic (TempMean + Humidity)\",\n    log_reg,\n    X_train, y_train,\n    X_val,   y_val,\n    X_test,  y_test\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:11:20.281240Z","iopub.execute_input":"2025-11-23T11:11:20.281511Z","iopub.status.idle":"2025-11-23T11:11:20.397511Z","shell.execute_reply.started":"2025-11-23T11:11:20.281496Z","shell.execute_reply":"2025-11-23T11:11:20.396496Z"}},"outputs":[{"name":"stdout","text":"\n==== Logistic (TempMean + Humidity) ====\nTrain: Acc=0.648, AUC=0.758\nVal: Acc=0.651, AUC=0.763\nTest: Acc=0.694, AUC=0.771\n\n--- Classification report (Test) ---\n              precision    recall  f1-score   support\n\n           0       0.97      0.69      0.81     33894\n           1       0.15      0.71      0.24      2490\n\n    accuracy                           0.69     36384\n   macro avg       0.56      0.70      0.52     36384\nweighted avg       0.91      0.69      0.77     36384\n\n\n--- Confusion matrix (Test) ---\n[[23470 10424]\n [  717  1773]]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"coef = log_reg.coef_.reshape(-1)    # [w_TempMean, w_Humidity]\nintercept = float(log_reg.intercept_[0])\n\nfeature_names = [\"TempMean\", \"Humidity\"]\nprint(\"Intercept (bias):\", intercept)\nfor name, w in zip(feature_names, coef):\n    print(f\"Weight for {name}: {w:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T11:11:27.749495Z","iopub.execute_input":"2025-11-23T11:11:27.749822Z","iopub.status.idle":"2025-11-23T11:11:27.754841Z","shell.execute_reply.started":"2025-11-23T11:11:27.749807Z","shell.execute_reply":"2025-11-23T11:11:27.754131Z"}},"outputs":[{"name":"stdout","text":"Intercept (bias): -18.49602386139671\nWeight for TempMean: 0.235201\nWeight for Humidity: 0.151022\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}